version: '3.8'

services:
  # Qdrant - Vector database
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: kb-api-qdrant
    restart: unless-stopped
    ports:
      - "${QDRANT_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__LOG_LEVEL: INFO
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:6333/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - kb-network

  # KB API Service
  kb-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: kb-api-service
    restart: unless-stopped
    ports:
      - "${KB_API_PORT:-3001}:3001"
    environment:
      # App configuration
      NODE_ENV: ${NODE_ENV:-production}
      KB_API_PORT: 3001
      LOG_LEVEL: ${LOG_LEVEL:-info}

      # CORS
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:3000}

      # Upload configuration
      MAX_FILE_SIZE: ${MAX_FILE_SIZE:-10485760}
      UPLOAD_DIR: /app/uploads

      # Qdrant configuration
      QDRANT_URL: http://qdrant:6333
      QDRANT_API_KEY: ${QDRANT_API_KEY:-}
      QDRANT_COLLECTION: ${QDRANT_COLLECTION:-llm_observatory_kb}
      VECTOR_SIZE: ${VECTOR_SIZE:-1536}
      QDRANT_DISTANCE: ${QDRANT_DISTANCE:-Cosine}

      # OpenAI configuration
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_EMBEDDING_MODEL: ${OPENAI_EMBEDDING_MODEL:-text-embedding-3-small}
      OPENAI_MAX_TOKENS: ${OPENAI_MAX_TOKENS:-8191}
      OPENAI_TIMEOUT: ${OPENAI_TIMEOUT:-30000}

      # Observatory configuration
      OBSERVATORY_ENABLED: ${OBSERVATORY_ENABLED:-true}
      OBSERVATORY_COLLECTOR_URL: ${OBSERVATORY_COLLECTOR_URL:-http://collector:4318}
      OBSERVATORY_SERVICE_NAME: kb-api
      OBSERVATORY_SERVICE_VERSION: 0.1.0
    volumes:
      - kb_uploads:/app/uploads
      - kb_logs:/app/logs
    depends_on:
      qdrant:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - kb-network
      - llm-observatory-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # KB API Development Service
  kb-api-dev:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: kb-api-dev
    restart: unless-stopped
    ports:
      - "${KB_API_DEV_PORT:-3002}:3001"
    environment:
      NODE_ENV: development
      KB_API_PORT: 3001
      LOG_LEVEL: debug
      CORS_ORIGINS: "*"
      MAX_FILE_SIZE: 10485760
      UPLOAD_DIR: /app/uploads
      QDRANT_URL: http://qdrant:6333
      QDRANT_COLLECTION: llm_observatory_kb_dev
      VECTOR_SIZE: 1536
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_EMBEDDING_MODEL: text-embedding-3-small
      OBSERVATORY_ENABLED: true
      OBSERVATORY_COLLECTOR_URL: http://collector:4318
    volumes:
      # Mount source code for hot reload
      - ./src:/app/src:cached
      - ./package*.json:/app/:ro
      - ./tsconfig.json:/app/tsconfig.json:ro
      - kb_uploads_dev:/app/uploads
      - kb_logs_dev:/app/logs
      # Node modules cache
      - kb_node_modules_dev:/app/node_modules
    depends_on:
      qdrant:
        condition: service_healthy
    networks:
      - kb-network
      - llm-observatory-network
    profiles:
      - dev

networks:
  kb-network:
    driver: bridge
    name: kb-network
  llm-observatory-network:
    external: true
    name: llm-observatory-network

volumes:
  qdrant_data:
    name: kb-api-qdrant-data
  kb_uploads:
    name: kb-api-uploads
  kb_logs:
    name: kb-api-logs
  kb_uploads_dev:
    name: kb-api-uploads-dev
  kb_logs_dev:
    name: kb-api-logs-dev
  kb_node_modules_dev:
    name: kb-api-node-modules-dev
