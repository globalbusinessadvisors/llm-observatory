version: '3.8'

services:
  # TimescaleDB - PostgreSQL with time-series extensions
  timescaledb:
    image: timescale/timescaledb:2.14.2-pg16
    container_name: llm-observatory-db
    restart: unless-stopped
    ports:
      - "${DB_PORT:-5432}:5432"
    environment:
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_DB: ${DB_NAME:-llm_observatory}
      # TimescaleDB specific settings
      TIMESCALEDB_TELEMETRY: "off"
      # Performance tuning for development
      POSTGRES_SHARED_BUFFERS: ${DB_SHARED_BUFFERS:-256MB}
      POSTGRES_WORK_MEM: ${DB_WORK_MEM:-32MB}
      POSTGRES_MAINTENANCE_WORK_MEM: ${DB_MAINTENANCE_WORK_MEM:-128MB}
      POSTGRES_EFFECTIVE_CACHE_SIZE: ${DB_EFFECTIVE_CACHE_SIZE:-1GB}
    volumes:
      # Persistent data storage
      - timescaledb_data:/var/lib/postgresql/data
      # Initialization scripts
      - ./docker/init:/docker-entrypoint-initdb.d:ro
      # Optional: Custom PostgreSQL configuration
      # - ./docker/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres} -d ${DB_NAME:-llm_observatory}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - llm-observatory-network
    command: >
      postgres
      -c shared_preload_libraries=timescaledb
      -c max_connections=200
      -c log_statement=mod
      -c log_duration=on
      -c log_min_duration_statement=1000

  # Redis - Caching and session storage
  redis:
    image: redis:7.2-alpine
    container_name: llm-observatory-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD:-redis_password}
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    networks:
      - llm-observatory-network
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-redis_password}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec

  # Storage Service - Database layer with COPY protocol optimization
  storage:
    build:
      context: .
      dockerfile: docker/Dockerfile.storage
    container_name: llm-observatory-storage
    restart: unless-stopped
    ports:
      # Internal API port for health and admin endpoints
      - "${STORAGE_API_PORT:-8082}:8080"
      # Prometheus metrics endpoint
      - "${STORAGE_METRICS_PORT:-9092}:9090"
    environment:
      # Environment
      ENVIRONMENT: ${ENVIRONMENT:-production}
      RUST_LOG: ${STORAGE_RUST_LOG:-info,llm_observatory_storage=debug,sqlx=warn}
      LOG_FORMAT: ${LOG_FORMAT:-json}

      # Database configuration
      DATABASE_URL: postgresql://${DB_APP_USER:-llm_observatory_app}:${DB_APP_PASSWORD:-change_me_in_production}@timescaledb:5432/${DB_NAME:-llm_observatory}

      # Connection pool settings
      DB_POOL_MIN_SIZE: ${DB_POOL_MIN_SIZE:-5}
      DB_POOL_MAX_SIZE: ${DB_POOL_MAX_SIZE:-20}
      DB_POOL_TIMEOUT: ${DB_POOL_TIMEOUT:-30}
      DB_POOL_IDLE_TIMEOUT: ${DB_POOL_IDLE_TIMEOUT:-300}
      DB_POOL_MAX_LIFETIME: ${DB_POOL_MAX_LIFETIME:-1800}

      # COPY protocol optimization settings
      COPY_BATCH_SIZE: ${COPY_BATCH_SIZE:-10000}
      COPY_FLUSH_INTERVAL: ${COPY_FLUSH_INTERVAL:-1000}
      COPY_BUFFER_SIZE: ${COPY_BUFFER_SIZE:-8192}
      COPY_MAX_RETRIES: ${COPY_MAX_RETRIES:-3}
      COPY_RETRY_DELAY_MS: ${COPY_RETRY_DELAY_MS:-100}

      # Redis configuration (optional)
      REDIS_URL: redis://:${REDIS_PASSWORD:-redis_password}@redis:6379/0

      # Server configuration
      APP_HOST: 0.0.0.0
      APP_PORT: 8080
      METRICS_PORT: 9090
      HEALTH_CHECK_ENABLED: true
      METRICS_ENABLED: true

      # Data retention settings
      RETENTION_TRACES_DAYS: ${RETENTION_TRACES_DAYS:-30}
      RETENTION_METRICS_DAYS: ${RETENTION_METRICS_DAYS:-90}
      RETENTION_LOGS_DAYS: ${RETENTION_LOGS_DAYS:-7}

      # Migration settings
      SKIP_MIGRATIONS: ${SKIP_MIGRATIONS:-false}
    volumes:
      # Read-only access to migration files (for production migrations)
      - ./crates/storage/migrations:/app/migrations:ro
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Storage Service (Development) - With hot reload and dev tools
  storage-dev:
    build:
      context: .
      dockerfile: docker/Dockerfile.storage.dev
    container_name: llm-observatory-storage-dev
    restart: unless-stopped
    ports:
      # Internal API port for health and admin endpoints
      - "${STORAGE_API_PORT:-8082}:8080"
      # Prometheus metrics endpoint
      - "${STORAGE_METRICS_PORT:-9092}:9090"
    environment:
      # Environment
      ENVIRONMENT: ${ENVIRONMENT:-development}
      RUST_LOG: ${STORAGE_RUST_LOG:-debug,llm_observatory_storage=debug,sqlx=info}
      LOG_FORMAT: text

      # Database configuration
      DATABASE_URL: postgresql://${DB_APP_USER:-llm_observatory_app}:${DB_APP_PASSWORD:-change_me_in_production}@timescaledb:5432/${DB_NAME:-llm_observatory}

      # Connection pool settings (smaller for dev)
      DB_POOL_MIN_SIZE: 2
      DB_POOL_MAX_SIZE: 10
      DB_POOL_TIMEOUT: 30

      # COPY protocol settings (smaller batches for dev)
      COPY_BATCH_SIZE: 1000
      COPY_FLUSH_INTERVAL: 500
      COPY_BUFFER_SIZE: 4096

      # Redis configuration
      REDIS_URL: redis://:${REDIS_PASSWORD:-redis_password}@redis:6379/0

      # Server configuration
      APP_HOST: 0.0.0.0
      APP_PORT: 8080
      METRICS_PORT: 9090
      HEALTH_CHECK_ENABLED: true
      METRICS_ENABLED: true

      # Development features
      AUTO_RELOAD: true
      DEBUG: true
      DB_QUERY_LOGGING: true

      # Migration settings
      SKIP_MIGRATIONS: ${SKIP_MIGRATIONS:-false}
    volumes:
      # Mount source code for hot reload
      - ./crates:/app/crates
      - ./Cargo.toml:/app/Cargo.toml
      - ./Cargo.lock:/app/Cargo.lock
      # Persistent cargo cache
      - storage-target:/app/target
      - storage-cargo-registry:/usr/local/cargo/registry
      - storage-cargo-git:/usr/local/cargo/git
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    profiles:
      - dev  # Only start with --profile dev

  # API Service - Production (REST & GraphQL)
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
      args:
        RUST_VERSION: 1.83
    image: llm-observatory-api:latest
    container_name: llm-observatory-api
    restart: unless-stopped
    ports:
      - "${API_PORT:-8080}:8080"
      - "${API_METRICS_PORT:-9091}:9090"
    environment:
      # Server configuration
      ENVIRONMENT: ${ENVIRONMENT:-production}
      APP_HOST: 0.0.0.0
      APP_PORT: 8080
      METRICS_PORT: 9090

      # Database configuration (read-only user)
      DATABASE_URL: postgresql://${DB_READONLY_USER:-llm_observatory_readonly}:${DB_READONLY_PASSWORD:-change_me_readonly}@timescaledb:5432/${DB_NAME:-llm_observatory}
      DB_POOL_MIN_SIZE: ${DB_POOL_MIN_SIZE:-5}
      DB_POOL_MAX_SIZE: ${DB_POOL_MAX_SIZE:-20}
      DB_POOL_TIMEOUT: ${DB_POOL_TIMEOUT:-30}
      DB_QUERY_LOGGING: ${DB_QUERY_LOGGING:-false}

      # Redis configuration
      REDIS_URL: redis://:${REDIS_PASSWORD:-redis_password}@redis:6379/${REDIS_DB:-0}
      CACHE_DEFAULT_TTL: ${CACHE_DEFAULT_TTL:-3600}
      CACHE_SHORT_TTL: ${CACHE_SHORT_TTL:-300}
      CACHE_LONG_TTL: ${CACHE_LONG_TTL:-86400}

      # Security configuration
      JWT_SECRET: ${JWT_SECRET:-change_me_to_a_random_jwt_secret}
      JWT_ALGORITHM: ${JWT_ALGORITHM:-HS256}
      JWT_EXPIRATION: ${JWT_EXPIRATION:-3600}
      SECRET_KEY: ${SECRET_KEY:-change_me_to_a_random_secret_key_in_production}

      # CORS configuration
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:3000,http://localhost:8080}
      CORS_MAX_AGE: ${CORS_MAX_AGE:-3600}

      # Rate limiting
      RATE_LIMIT_REQUESTS: ${RATE_LIMIT_REQUESTS:-100}
      RATE_LIMIT_WINDOW: ${RATE_LIMIT_WINDOW:-60}
      RATE_LIMIT_ENABLED: ${RATE_LIMIT_ENABLED:-true}

      # GraphQL configuration
      GRAPHQL_ENABLED: ${GRAPHQL_ENABLED:-true}
      GRAPHQL_PLAYGROUND: ${GRAPHQL_PLAYGROUND:-false}
      GRAPHQL_INTROSPECTION: ${GRAPHQL_INTROSPECTION:-false}
      GRAPHQL_MAX_DEPTH: ${GRAPHQL_MAX_DEPTH:-10}
      GRAPHQL_MAX_COMPLEXITY: ${GRAPHQL_MAX_COMPLEXITY:-1000}

      # Logging
      RUST_LOG: ${LOG_LEVEL:-info}
      LOG_FORMAT: ${LOG_FORMAT:-json}

      # Metrics & monitoring
      METRICS_ENABLED: ${METRICS_ENABLED:-true}
      HEALTH_CHECK_ENABLED: ${HEALTH_CHECK_ENABLED:-true}

      # Error tracking
      SENTRY_DSN: ${SENTRY_DSN:-}
      SENTRY_ENVIRONMENT: ${ENVIRONMENT:-production}
    volumes:
      # Read-only configuration
      - ./docker/api-config.yml:/app/config/api-config.yml:ro
    healthcheck:
      test: ["CMD", "/app/llm-observatory-api", "health-check"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    # Security options
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    read_only: false  # Set to true if stateless
    tmpfs:
      - /tmp:noexec,nosuid,size=100m

  # API Service - Development (with hot reload)
  api-dev:
    build:
      context: .
      dockerfile: docker/Dockerfile.api.dev
    image: llm-observatory-api:dev
    container_name: llm-observatory-api-dev
    restart: unless-stopped
    ports:
      - "${API_DEV_PORT:-8081}:8080"
      - "${API_DEV_METRICS_PORT:-9092}:9090"
      - "${GRAPHQL_PLAYGROUND_PORT:-5555}:5555"
    environment:
      # Server configuration
      ENVIRONMENT: development
      APP_HOST: 0.0.0.0
      APP_PORT: 8080
      METRICS_PORT: 9090
      DEBUG: "true"

      # Database configuration (read-only user)
      DATABASE_URL: postgresql://${DB_READONLY_USER:-llm_observatory_readonly}:${DB_READONLY_PASSWORD:-change_me_readonly}@timescaledb:5432/${DB_NAME:-llm_observatory}
      DB_POOL_MIN_SIZE: 2
      DB_POOL_MAX_SIZE: 10
      DB_QUERY_LOGGING: "true"

      # Redis configuration
      REDIS_URL: redis://:${REDIS_PASSWORD:-redis_password}@redis:6379/${REDIS_DB:-0}
      CACHE_DEFAULT_TTL: 300

      # Security configuration (relaxed for development)
      JWT_SECRET: dev_jwt_secret_not_for_production
      JWT_EXPIRATION: 86400
      SECRET_KEY: dev_secret_key_not_for_production

      # CORS configuration (permissive for development)
      CORS_ORIGINS: "*"

      # Rate limiting (disabled for development)
      RATE_LIMIT_ENABLED: "false"

      # GraphQL configuration
      GRAPHQL_ENABLED: "true"
      GRAPHQL_PLAYGROUND: "true"
      GRAPHQL_INTROSPECTION: "true"
      GRAPHQL_MAX_DEPTH: 20

      # Logging
      RUST_LOG: debug
      RUST_BACKTRACE: full
      LOG_FORMAT: pretty

      # Metrics & monitoring
      METRICS_ENABLED: "true"
    volumes:
      # Mount source code for hot reload
      - ./crates:/app/crates:cached
      - ./Cargo.toml:/app/Cargo.toml:ro
      - ./Cargo.lock:/app/Cargo.lock:ro
      # Cargo cache for faster rebuilds
      - cargo_cache:/usr/local/cargo/registry
      - cargo_git_cache:/usr/local/cargo/git
      - api_dev_target:/app/target
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 30s
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    profiles:
      - dev  # Only start with --profile dev

  # Prometheus - Metrics collection and storage
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: llm-observatory-prometheus
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - prometheus_data:/prometheus
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./docker/prometheus/alerts:/etc/prometheus/alerts:ro
      - ./docker/prometheus/rules:/etc/prometheus/rules:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - llm-observatory-network
    depends_on:
      - postgres-exporter
      - redis-exporter

  # Alertmanager - Alert routing and notification
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: llm-observatory-alertmanager
    restart: unless-stopped
    ports:
      - "${ALERTMANAGER_PORT:-9093}:9093"
    volumes:
      - alertmanager_data:/alertmanager
      - ./docker/prometheus/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - llm-observatory-network

  # PostgreSQL Exporter - Database metrics
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.15.0
    container_name: llm-observatory-postgres-exporter
    restart: unless-stopped
    ports:
      - "${POSTGRES_EXPORTER_PORT:-9187}:9187"
    environment:
      DATA_SOURCE_NAME: "postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@timescaledb:5432/${DB_NAME:-llm_observatory}?sslmode=disable"
      PG_EXPORTER_EXTEND_QUERY_PATH: "/etc/postgres_exporter/queries.yaml"
    volumes:
      - ./docker/exporters/postgres-queries.yaml:/etc/postgres_exporter/queries.yaml:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy

  # Redis Exporter - Cache metrics
  redis-exporter:
    image: oliver006/redis_exporter:v1.55.0
    container_name: llm-observatory-redis-exporter
    restart: unless-stopped
    ports:
      - "${REDIS_EXPORTER_PORT:-9121}:9121"
    environment:
      REDIS_ADDR: "redis:6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-redis_password}
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9121/metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - llm-observatory-network
    depends_on:
      redis:
        condition: service_healthy

  # Node Exporter - System metrics
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: llm-observatory-node-exporter
    restart: unless-stopped
    ports:
      - "${NODE_EXPORTER_PORT:-9100}:9100"
    command:
      - '--path.rootfs=/host'
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /:/host:ro,rslave
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - llm-observatory-network

  # Jaeger - Distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: llm-observatory-jaeger
    restart: unless-stopped
    ports:
      # Jaeger UI
      - "${JAEGER_UI_PORT:-16686}:16686"
      # OTLP gRPC receiver
      - "${JAEGER_OTLP_GRPC_PORT:-4317}:4317"
      # OTLP HTTP receiver
      - "${JAEGER_OTLP_HTTP_PORT:-4318}:4318"
      # Jaeger Thrift compact
      - "${JAEGER_COMPACT_PORT:-6831}:6831/udp"
      # Jaeger Thrift binary
      - "${JAEGER_BINARY_PORT:-6832}:6832/udp"
      # Jaeger gRPC
      - "${JAEGER_GRPC_PORT:-14250}:14250"
      # HTTP collector
      - "${JAEGER_COLLECTOR_PORT:-14268}:14268"
    environment:
      # Span storage configuration
      SPAN_STORAGE_TYPE: badger
      BADGER_EPHEMERAL: "false"
      BADGER_DIRECTORY_VALUE: /badger/data
      BADGER_DIRECTORY_KEY: /badger/key
      # Collector configuration
      COLLECTOR_OTLP_ENABLED: "true"
      # Query configuration
      QUERY_BASE_PATH: /jaeger
      # Sampling configuration
      SAMPLING_STRATEGIES_FILE: /etc/jaeger/sampling.json
    volumes:
      - jaeger_data:/badger
      - ./docker/jaeger/sampling.json:/etc/jaeger/sampling.json:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:14269/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - llm-observatory-network

  # Loki - Log aggregation
  loki:
    image: grafana/loki:2.9.3
    container_name: llm-observatory-loki
    restart: unless-stopped
    ports:
      - "${LOKI_PORT:-3100}:3100"
    volumes:
      - loki_data:/loki
      - ./docker/loki/loki-config.yml:/etc/loki/local-config.yaml:ro
    command: -config.file=/etc/loki/local-config.yaml
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - llm-observatory-network

  # Promtail - Log collector for Loki
  promtail:
    image: grafana/promtail:2.9.3
    container_name: llm-observatory-promtail
    restart: unless-stopped
    volumes:
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./docker/loki/promtail-config.yml:/etc/promtail/config.yml:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - llm-observatory-network
    depends_on:
      loki:
        condition: service_healthy

  # Grafana - Visualization and dashboards
  grafana:
    image: grafana/grafana:10.4.1
    container_name: llm-observatory-grafana
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      # Admin credentials
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      # Server settings
      GF_SERVER_ROOT_URL: ${GRAFANA_ROOT_URL:-http://localhost:3000}
      GF_SERVER_DOMAIN: ${GRAFANA_DOMAIN:-localhost}
      # Database configuration (using TimescaleDB for Grafana's metadata)
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: timescaledb:5432
      GF_DATABASE_NAME: ${GRAFANA_DB_NAME:-grafana}
      GF_DATABASE_USER: ${DB_USER:-postgres}
      GF_DATABASE_PASSWORD: ${DB_PASSWORD:-postgres}
      GF_DATABASE_SSL_MODE: disable
      # Authentication
      GF_AUTH_ANONYMOUS_ENABLED: ${GRAFANA_ANONYMOUS_ENABLED:-false}
      # Plugins
      GF_INSTALL_PLUGINS: ${GRAFANA_PLUGINS:-grafana-piechart-panel}
      # Disable telemetry
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_ANALYTICS_CHECK_FOR_UPDATES: "false"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./docker/grafana/dashboards:/var/lib/grafana/dashboards:ro
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
      jaeger:
        condition: service_healthy

  # PgAdmin - Optional database administration UI
  pgadmin:
    image: dpage/pgadmin4:8.4
    container_name: llm-observatory-pgadmin
    restart: unless-stopped
    ports:
      - "${PGADMIN_PORT:-5050}:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@llm-observatory.local}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: "False"
      PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED: "False"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    healthcheck:
      test: ["CMD", "wget", "-O", "-", "http://localhost:80/misc/ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy
    profiles:
      - admin  # Only start with --profile admin

  # CLI Tools - Database management and utilities
  cli:
    build:
      context: .
      dockerfile: docker/Dockerfile.cli
    container_name: llm-observatory-cli
    restart: "no"  # Only run on demand
    environment:
      # Database connection
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: ${DB_NAME:-llm_observatory}
      DB_USER: ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@timescaledb:5432/${DB_NAME:-llm_observatory}
      # Paths
      MIGRATIONS_DIR: /app/migrations
      SCRIPTS_DIR: /app/scripts
      BACKUPS_DIR: /app/backups
      DATA_DIR: /app/data
      # Configuration
      LOG_LEVEL: ${LOG_LEVEL:-info}
      RUST_LOG: ${RUST_LOG:-sqlx=info}
      # Backup retention
      BACKUP_RETENTION_DAYS: ${BACKUP_RETENTION:-30}
      # AWS S3 configuration (optional)
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      S3_BACKUP_BUCKET: ${S3_BACKUP_BUCKET:-}
      S3_BACKUP_PREFIX: ${S3_BACKUP_PREFIX:-backups/}
    volumes:
      # Migrations (read-only)
      - ./crates/storage/migrations:/app/migrations:ro
      # Utility scripts (read-only)
      - ./docker/scripts/utilities:/app/scripts:ro
      # Backup storage
      - backup_data:/app/backups
      # Data directory for seed files, etc.
      - ./docker/data:/app/data:ro
      # Configuration (read-only)
      - ./.env:/app/.env:ro
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy
    profiles:
      - tools  # Start with --profile tools
    # Override command as needed:
    # docker compose --profile tools run --rm cli migrate
    # docker compose --profile tools run --rm cli seed
    # docker compose --profile tools run --rm cli backup

  # Backup Service - Automated database backups
  backup:
    image: postgres:16-alpine
    container_name: llm-observatory-backup
    restart: "no"  # Only run on demand or via cron
    environment:
      PGHOST: timescaledb
      PGPORT: 5432
      PGDATABASE: ${DB_NAME:-llm_observatory}
      PGUSER: ${DB_USER:-postgres}
      PGPASSWORD: ${DB_PASSWORD:-postgres}
      # Backup configuration
      BACKUP_RETENTION_DAYS: ${BACKUP_RETENTION:-30}
      # AWS S3 configuration (optional)
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      S3_BACKUP_BUCKET: ${S3_BACKUP_BUCKET:-}
      S3_BACKUP_PREFIX: ${S3_BACKUP_PREFIX:-backups/}
    volumes:
      # Backup storage
      - backup_data:/backups
      # Backup scripts
      - ./scripts:/scripts:ro
      # Configuration
      - ./.env:/app/.env:ro
    networks:
      - llm-observatory-network
    depends_on:
      timescaledb:
        condition: service_healthy
    profiles:
      - backup  # Only start with --profile backup
    entrypoint: ["/bin/sh"]
    command:
      - -c
      - |
        # Install required tools
        apk add --no-cache bash gzip aws-cli

        # Run backup script
        if [ -f /scripts/backup.sh ]; then
          bash /scripts/backup.sh -c /app/.env -d /backups -v
        else
          echo "Backup script not found"
          exit 1
        fi

networks:
  llm-observatory-network:
    driver: bridge
    name: llm-observatory-network

volumes:
  timescaledb_data:
    name: llm-observatory-db-data
  redis_data:
    name: llm-observatory-redis-data
  prometheus_data:
    name: llm-observatory-prometheus-data
  alertmanager_data:
    name: llm-observatory-alertmanager-data
  jaeger_data:
    name: llm-observatory-jaeger-data
  loki_data:
    name: llm-observatory-loki-data
  grafana_data:
    name: llm-observatory-grafana-data
  pgadmin_data:
    name: llm-observatory-pgadmin-data
  backup_data:
    name: llm-observatory-backup-data
  # API Development volumes
  cargo_cache:
    name: llm-observatory-cargo-cache
  cargo_git_cache:
    name: llm-observatory-cargo-git-cache
  api_dev_target:
    name: llm-observatory-api-dev-target
  # Storage Service development volumes
  storage-target:
    name: llm-observatory-storage-target
  storage-cargo-registry:
    name: llm-observatory-storage-cargo-registry
  storage-cargo-git:
    name: llm-observatory-storage-cargo-git
